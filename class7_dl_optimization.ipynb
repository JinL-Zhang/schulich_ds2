{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Obtaining dependency information for tensorflow_datasets from https://files.pythonhosted.org/packages/a1/73/7a9ed7935f6833d73b32f1e2a1210082f5ccb95445440b4e2b0f66ab7792/tensorflow_datasets-4.9.3-py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_datasets-4.9.3-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (2.0.0)\n",
      "Collecting array-record (from tensorflow_datasets)\n",
      "  Obtaining dependency information for array-record from https://files.pythonhosted.org/packages/93/8e/c6b646029a9c544ecd6806c6ea0efb67d0ba3300e1d68518f58d9774d3f0/array_record-0.4.1-py310-none-any.whl.metadata\n",
      "  Downloading array_record-0.4.1-py310-none-any.whl.metadata (503 bytes)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (8.1.7)\n",
      "Collecting dm-tree (from tensorflow_datasets)\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-macosx_10_9_x86_64.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.4/115.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting etils[enp,epath,etree]>=0.9.0 (from tensorflow_datasets)\n",
      "  Obtaining dependency information for etils[enp,epath,etree]>=0.9.0 from https://files.pythonhosted.org/packages/0f/6a/d2aaebacf73d5da7126c632ec0d9dc2df99cc4bbd259bad48904a034fc1b/etils-1.5.2-py3-none-any.whl.metadata\n",
      "  Downloading etils-1.5.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (1.25.0)\n",
      "Collecting promise (from tensorflow_datasets)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (4.25.0)\n",
      "Requirement already satisfied: psutil in /Users/delinaivanova/Library/Python/3.11/lib/python/site-packages (from tensorflow_datasets) (5.9.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (2.31.0)\n",
      "Collecting tensorflow-metadata (from tensorflow_datasets)\n",
      "  Obtaining dependency information for tensorflow-metadata from https://files.pythonhosted.org/packages/41/23/3705c7139886c079ef4c0e3be56a5a1fb90e9ee413a4b7caaee0ee0ea6fe/tensorflow_metadata-1.14.0-py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_metadata-1.14.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (2.3.0)\n",
      "Collecting toml (from tensorflow_datasets)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (4.66.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (1.14.1)\n",
      "Collecting fsspec (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting importlib_resources (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets)\n",
      "  Obtaining dependency information for importlib_resources from https://files.pythonhosted.org/packages/93/e8/facde510585869b5ec694e8e0363ffe4eba067cb357a8398a55f6a1f8023/importlib_resources-6.1.1-py3-none-any.whl.metadata\n",
      "  Downloading importlib_resources-6.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (4.8.0)\n",
      "Collecting zipp (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets)\n",
      "  Obtaining dependency information for zipp from https://files.pythonhosted.org/packages/d9/66/48866fc6b158c81cc2bfecc04c480f105c6040e8b077bc54c634b4a67926/zipp-3.17.0-py3-none-any.whl.metadata\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (2023.7.22)\n",
      "Requirement already satisfied: six in /Users/delinaivanova/Library/Python/3.11/lib/python/site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Collecting absl-py (from tensorflow_datasets)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting googleapis-common-protos<2,>=1.52.0 (from tensorflow-metadata->tensorflow_datasets)\n",
      "  Obtaining dependency information for googleapis-common-protos<2,>=1.52.0 from https://files.pythonhosted.org/packages/21/49/12996dc0238e017504dceea1d121a48bd49fb3f4416f40d59fc3e924b4f3/googleapis_common_protos-1.61.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf>=3.20 (from tensorflow_datasets)\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_datasets-4.9.3-py3-none-any.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading array_record-0.4.1-py310-none-any.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_metadata-1.14.0-py3-none-any.whl (28 kB)\n",
      "Downloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl (230 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.9/230.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading etils-1.5.2-py3-none-any.whl (140 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21484 sha256=1cd8596b27ccdef44cf4f9270ea5a101264405168114b6c3d8f89da782981b66\n",
      "  Stored in directory: /Users/delinaivanova/Library/Caches/pip/wheels/90/74/b1/9b54c896b8d9409e9268329d4d45ede8a8040abe91c8879932\n",
      "Successfully built promise\n",
      "Installing collected packages: dm-tree, zipp, toml, protobuf, promise, importlib_resources, fsspec, etils, absl-py, googleapis-common-protos, tensorflow-metadata, array-record, tensorflow_datasets\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.0\n",
      "    Uninstalling protobuf-4.25.0:\n",
      "      Successfully uninstalled protobuf-4.25.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 2.0.0\n",
      "    Uninstalling absl-py-2.0.0:\n",
      "      Successfully uninstalled absl-py-2.0.0\n",
      "Successfully installed absl-py-1.4.0 array-record-0.4.1 dm-tree-0.1.8 etils-1.5.2 fsspec-2023.10.0 googleapis-common-protos-1.61.0 importlib_resources-6.1.1 promise-2.3 protobuf-3.20.3 tensorflow-metadata-1.14.0 tensorflow_datasets-4.9.3 toml-0.10.2 zipp-3.17.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = tfds.load('mnist',\n",
    "                                split = ['train','test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def load_dataset(train_size, test_size):\n",
    "    train, test = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    # take a sample\n",
    "    train_idx = np.random.randint(low=0, high=train[0].shape[0], size=train_size)\n",
    "    test_idx = np.random.randint(low=0, high=test[0].shape[0], size=test_size)\n",
    "    X_train = train[0][train_idx].reshape(-1,28*28)\n",
    "    y_train = train[1][train_idx].reshape(-1,1)\n",
    "    X_test = test[0][test_idx].reshape(-1,28*28)\n",
    "    y_test = test[1][test_idx].reshape(-1,1)\n",
    "\n",
    "    scale = StandardScaler()\n",
    "    X_train = scale.fit_transform(X_train)\n",
    "    X_test = scale.transform(X_test)\n",
    "\n",
    "    OH = OneHotEncoder(categories='auto', sparse=False)\n",
    "    y_train = OH.fit_transform(y_train)\n",
    "    y_test = OH.transform(y_test)\n",
    "\n",
    "    print('X_train:',X_train.shape)\n",
    "    print('y_train:',y_train.shape)\n",
    "    print('X_test:',X_test.shape)\n",
    "    print('y_test:',y_test.shape)\n",
    "    print('Min:', X_train.min())\n",
    "    print('Max:', X_train.max())\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 784)\n",
      "y_train: (60000, 10)\n",
      "X_test: (10000, 784)\n",
      "y_test: (10000, 10)\n",
      "Min: -1.2716186854969616\n",
      "Max: 244.94693302857712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_dataset(60000,10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing at the Initialization Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(initializer, activation='relu'):\n",
    "    return tf.keras.Sequential([layers.Dense(32, activation, input_shape=(784,), kernel_initializer=initializer),\n",
    "                                layers.Dense(32, activation, kernel_initializer=initializer),\n",
    "                                layers.Dense(32, activation, kernel_initializer=initializer),\n",
    "                                layers.Dense(32, activation, kernel_initializer=initializer),\n",
    "                                layers.Dense(10, activation = 'softmax', kernel_initializer=tf.keras.initializers.glorot_normal())\n",
    "\n",
    "\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.initializers.zeros()\n",
    "activate = 'relu'\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "model_zeros = simple_model(init, activate)\n",
    "model_zeros.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_zeros.fit(X_train, y_train, epochs=10, batch_size=3200, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 2.3025 - accuracy: 0.1155 - val_loss: 2.3025 - val_accuracy: 0.1144\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 2.3025 - accuracy: 0.1163 - val_loss: 2.3025 - val_accuracy: 0.1144\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 2.3024 - accuracy: 0.1163 - val_loss: 2.3024 - val_accuracy: 0.1144\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 2.3023 - accuracy: 0.1163 - val_loss: 2.3024 - val_accuracy: 0.1144\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 2.3022 - accuracy: 0.1163 - val_loss: 2.3023 - val_accuracy: 0.1144\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 2.3022 - accuracy: 0.1163 - val_loss: 2.3023 - val_accuracy: 0.1144\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 2.3021 - accuracy: 0.1163 - val_loss: 2.3022 - val_accuracy: 0.1144\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 2.3020 - accuracy: 0.1163 - val_loss: 2.3022 - val_accuracy: 0.1144\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 2.3020 - accuracy: 0.1163 - val_loss: 2.3021 - val_accuracy: 0.1144\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 2.3019 - accuracy: 0.1163 - val_loss: 2.3021 - val_accuracy: 0.1144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x147a97b50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 2.3027 - accuracy: 0.0958 - val_loss: 2.3024 - val_accuracy: 0.1091\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 2.3022 - accuracy: 0.1204 - val_loss: 2.3021 - val_accuracy: 0.1174\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 2.3020 - accuracy: 0.1180 - val_loss: 2.3019 - val_accuracy: 0.1154\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 2.3017 - accuracy: 0.1167 - val_loss: 2.3017 - val_accuracy: 0.1150\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 2.3015 - accuracy: 0.1164 - val_loss: 2.3015 - val_accuracy: 0.1147\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 2.3013 - accuracy: 0.1163 - val_loss: 2.3014 - val_accuracy: 0.1144\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 2.3012 - accuracy: 0.1163 - val_loss: 2.3012 - val_accuracy: 0.1144\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 2.3010 - accuracy: 0.1163 - val_loss: 2.3010 - val_accuracy: 0.1144\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 2.3008 - accuracy: 0.1162 - val_loss: 2.3009 - val_accuracy: 0.1144\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 2.3006 - accuracy: 0.1162 - val_loss: 2.3007 - val_accuracy: 0.1144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x147b30310>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tf.initializers.random_normal()\n",
    "activate = 'relu'\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "model_normal = simple_model(init, activate)\n",
    "model_normal.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_normal.fit(X_train, y_train, epochs=10, batch_size=3200, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 2.3383 - accuracy: 0.1120 - val_loss: 2.3176 - val_accuracy: 0.1361\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 2.2861 - accuracy: 0.1450 - val_loss: 2.2699 - val_accuracy: 0.1649\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 2.2421 - accuracy: 0.1782 - val_loss: 2.2267 - val_accuracy: 0.1920\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 2.2000 - accuracy: 0.2051 - val_loss: 2.1837 - val_accuracy: 0.2134\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 2.1565 - accuracy: 0.2286 - val_loss: 2.1393 - val_accuracy: 0.2330\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 2.1104 - accuracy: 0.2500 - val_loss: 2.0923 - val_accuracy: 0.2520\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 2.0608 - accuracy: 0.2695 - val_loss: 2.0419 - val_accuracy: 0.2709\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 2.0071 - accuracy: 0.2916 - val_loss: 1.9870 - val_accuracy: 0.2960\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 1.9488 - accuracy: 0.3144 - val_loss: 1.9271 - val_accuracy: 0.3184\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 1.8852 - accuracy: 0.3393 - val_loss: 1.8611 - val_accuracy: 0.3436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1483df150>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tf.initializers.glorot_uniform()\n",
    "activate = 'relu'\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "model_glorotu = simple_model(init, activate)\n",
    "model_glorotu.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_glorotu.fit(X_train, y_train, epochs=10, batch_size=3200, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
